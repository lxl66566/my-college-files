在机器学习中，向量是一种基本的单位。它不仅仅存在于几何空间中，还广泛应用于数据表示、特征提取、模型训练等方方面面。从图像、文本到音频，一切数据都可以被表示成向量。


文本 Embedding 衡量文本字符串之间的相关性，是自然语言处理中的重要技术。通过将文本映射到高维向量空间，我们可以捕捉到词汇之间的语义关系。。Embedding 通常用于以下场景：

搜索（结果按查询字符串的相关性进行排序）
聚类（将文本字符串按相似性分组）
推荐（推荐具有相关文本字符串的项目）
异常检测（识别相关性较小的异常值）
多样性测量（分析相似度分布）
分类（文本字符串按其最相似的标签进行分类）

局部敏感哈希(Locality-Sensitive Hashing, LSH) LSH 所得到的是一个比 k-means 更加粗略的结果，主要运用到高维海量数据的快速近似查找


基本思想是：将原始数据空间中的两个相邻数据点通过相同的映射或投影变换（projection）后，这两个数据点在新的数据空间中仍然相邻的概率很大，而不相邻的数据点被映射到同一个空间的概率很小。

One-hot Encoding：
最简单的词向量表示方法。
每个词被表示为一个很长的向量，向量的长度等于词汇表的大小，其中只有一个元素是1，其余都是0。
缺点是无法表达词与词之间的相似性。